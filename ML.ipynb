{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb7e3f16-db35-4023-9e25-95dc72da42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8347fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Normal cases': 416, 'Malignant cases': 561, 'Bengin cases': 120}\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR=\"./Datasets/lung/\"\n",
    "number_of_images={}\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    number_of_images[dir]=len(os.listdir(os.path.join(ROOT_DIR,dir)))\n",
    "print(number_of_images)\n",
    "classes=list(number_of_images.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bf0c54d-51df-43e9-8490-55fd17fa9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datafolder(path,split):\n",
    "    if not os.path.exists('./'+path):\n",
    "        os.mkdir('./'+path)\n",
    "        for dir in os.listdir(ROOT_DIR):\n",
    "            os.makedirs(\"./\"+path+\"/\"+dir)\n",
    "            for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR,dir)),size=(math.floor(split*number_of_images[dir])),replace=False):\n",
    "                O=os.path.join(ROOT_DIR,dir,img)\n",
    "                D=os.path.join(\"./\"+path+\"/\",dir)\n",
    "                shutil.copy(O,D)\n",
    "    else :\n",
    "        print(path+\" Folder exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e53f476a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Folder exists\n",
      "val Folder exists\n",
      "test Folder exists\n"
     ]
    }
   ],
   "source": [
    "datafolder(\"train\",0.7)\n",
    "datafolder(\"val\",0.5)\n",
    "datafolder(\"test\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "394a235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization,GlobalAvgPool2D\n",
    "from keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9bcf10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 512, 512, 8)       224       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 510, 510, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 255, 255, 16)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 253, 253, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 126, 126, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 62, 62, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 246016)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                15745088  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15769811 (60.16 MB)\n",
      "Trainable params: 15769811 (60.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters= 8,kernel_size=(3,3),activation='relu',input_shape=(512,512,3),padding='same'))\n",
    "model.add(Conv2D(filters= 16,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters= 32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=64,activation='relu'))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b86dbbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25639736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 767 images belonging to 3 classes.\n",
      "Found 548 images belonging to 3 classes.\n",
      "Found 1097 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data=ImageDataGenerator(zoom_range=0.2,shear_range=0.2,rescale=1/255,horizontal_flip=True).flow_from_directory(directory='./train',target_size=(512,512),batch_size=32,class_mode='binary')\n",
    "val_data=ImageDataGenerator(rescale=1/255).flow_from_directory(directory='./val',target_size=(512,512),batch_size=32,class_mode='binary')\n",
    "test_data=ImageDataGenerator(rescale=1/255).flow_from_directory(directory='./test',target_size=(512,512),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78f43d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "es=EarlyStopping(monitor='val_accuracy',min_delta=0.01,patience=3,verbose=1,mode='auto') # type: ignore\n",
    "M=ModelCheckpoint(monitor='val_accuracy',filepath='./best.h5',verbose=1,save_best_only=True,mode='auto')\n",
    "cd=[es,M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c20dc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.0665 - accuracy: 0.3828\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71680, saving model to ./best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/share/Machine Learning/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 32s 4s/step - loss: 2.0665 - accuracy: 0.3828 - val_loss: 0.9277 - val_accuracy: 0.7168\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.9220 - accuracy: 0.5412\n",
      "Epoch 2: val_accuracy did not improve from 0.71680\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.9220 - accuracy: 0.5412 - val_loss: 0.8490 - val_accuracy: 0.6152\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8520 - accuracy: 0.6289\n",
      "Epoch 3: val_accuracy improved from 0.71680 to 0.74219, saving model to ./best.h5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 0.8520 - accuracy: 0.6289 - val_loss: 0.7799 - val_accuracy: 0.7422\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8455 - accuracy: 0.6549\n",
      "Epoch 4: val_accuracy did not improve from 0.74219\n",
      "8/8 [==============================] - 30s 4s/step - loss: 0.8455 - accuracy: 0.6549 - val_loss: 0.7872 - val_accuracy: 0.5742\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.8148 - accuracy: 0.6680"
     ]
    }
   ],
   "source": [
    "hs=model.fit(train_data,steps_per_epoch=8,epochs=10,verbose=1,validation_data=val_data,validation_steps=16,callbacks=cd) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafc9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 512, 512, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-206.80734  203.39685  185.69939]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/share/Machine Learning/ML.ipynb Cell 11\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.131.217.22/home/share/Machine%20Learning/ML.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m pred\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(arr)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.131.217.22/home/share/Machine%20Learning/ML.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(pred)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B34.131.217.22/home/share/Machine%20Learning/ML.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(classes[pred\u001b[39m.\u001b[39mindex(\u001b[39mmax\u001b[39m(pred))])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "img=load_img('Datasets/lung/Malignant cases/Malignant case (73).jpg',target_size=(512,512))\n",
    "arr=img_to_array(img)\n",
    "arr=np.expand_dims(arr,axis=0)\n",
    "print(arr.shape)\n",
    "pred=model.predict(arr)[0]\n",
    "print(pred)\n",
    "print(classes[pred.index(max(pred))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
