{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:38:30.359944: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:38:30.384540: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-23 23:38:30.384565: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-23 23:38:30.384580: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-23 23:38:30.389517: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from custom_fn import specificity,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('./Datasets/lung/').with_suffix('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 977 files belonging to 2 classes.\n",
      "Using 489 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:38:31.281476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.284374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.284485: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.285145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.285360: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.285425: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.335712: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.335814: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.335891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-23 23:38:31.335951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2687 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  label_mode=\"binary\",\n",
    "  seed=123,\n",
    "  image_size=(512, 512),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 977 files belonging to 2 classes.\n",
      "Using 390 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"validation\",\n",
    "  label_mode=\"binary\",\n",
    "  seed=123,\n",
    "  image_size=(512, 512),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 512, 512, 8)       392       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 510, 510, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 255, 255, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 253, 253, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 126, 126, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 124, 124, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 30, 30, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1843216   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1941913 (7.41 MB)\n",
      "Trainable params: 1941913 (7.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters= 8,kernel_size=(4,4),input_shape=(512,512,3),padding='same'))\n",
    "model.add(Conv2D(filters= 16,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(filters= 32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=16,activation='relu'))\n",
    "model.add(Dense(units=8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=keras.losses.BinaryCrossentropy(),\n",
    "  metrics=['accuracy',specificity,recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "es=EarlyStopping(monitor=\"val_accuracy\",min_delta=0.01,patience=6,verbose=1)\n",
    "mc=ModelCheckpoint(monitor=\"val_accuracy\",filepath=\"./bestmodel.h5\",save_best_only=True)\n",
    "cd=[es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 23:38:32.807971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2023-11-23 23:38:33.392653: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:33.417734: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.25GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:34.027746: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:34.194343: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:34.984116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f91b81b4e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-23 23:38:34.984139: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2023-11-23 23:38:34.987090: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-23 23:38:35.045354: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-11-23 23:38:36.234903: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 880.07MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:36.563245: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 880.07MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:36.745278: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:36.745307: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.02GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:36.907321: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-11-23 23:38:37.840279: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.70GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 24.8144 - accuracy: 0.5112 - specificity: 0.6046 - recall: 0.4023\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62051, saving model to ./bestmodel.h5\n",
      "16/16 [==============================] - 12s 397ms/step - loss: 24.8144 - accuracy: 0.5112 - specificity: 0.6046 - recall: 0.4023 - val_loss: 0.6146 - val_accuracy: 0.6205 - val_specificity: 1.0000 - val_recall: 0.0433\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/star/Projects/Machine Learning/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.3845 - accuracy: 0.8241 - specificity: 0.8995 - recall: 0.3746\n",
      "Epoch 2: val_accuracy improved from 0.62051 to 0.80769, saving model to ./bestmodel.h5\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.3845 - accuracy: 0.8241 - specificity: 0.8995 - recall: 0.3746 - val_loss: 0.3571 - val_accuracy: 0.8077 - val_specificity: 0.6487 - val_recall: 0.6210\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 0.9448 - specificity: 0.9532 - recall: 0.4251\n",
      "Epoch 3: val_accuracy improved from 0.80769 to 0.96923, saving model to ./bestmodel.h5\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.1340 - accuracy: 0.9448 - specificity: 0.9532 - recall: 0.4251 - val_loss: 0.1032 - val_accuracy: 0.9692 - val_specificity: 0.9945 - val_recall: 0.3958\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9877 - specificity: 0.9901 - recall: 0.4143\n",
      "Epoch 4: val_accuracy improved from 0.96923 to 0.99231, saving model to ./bestmodel.h5\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.0405 - accuracy: 0.9877 - specificity: 0.9901 - recall: 0.4143 - val_loss: 0.0283 - val_accuracy: 0.9923 - val_specificity: 0.9662 - val_recall: 0.4479\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9959 - specificity: 0.9970 - recall: 0.4293\n",
      "Epoch 5: val_accuracy did not improve from 0.99231\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.0247 - accuracy: 0.9959 - specificity: 0.9970 - recall: 0.4293 - val_loss: 0.0721 - val_accuracy: 0.9692 - val_specificity: 0.9435 - val_recall: 0.4383\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4093\n",
      "Epoch 6: val_accuracy did not improve from 0.99231\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.0099 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4093 - val_loss: 0.0341 - val_accuracy: 0.9846 - val_specificity: 0.9955 - val_recall: 0.3998\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 7.7811e-04 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4193\n",
      "Epoch 7: val_accuracy did not improve from 0.99231\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 7.7811e-04 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4193 - val_loss: 0.0268 - val_accuracy: 0.9897 - val_specificity: 0.9922 - val_recall: 0.4407\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0677e-04 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4093\n",
      "Epoch 8: val_accuracy did not improve from 0.99231\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 1.0677e-04 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4093 - val_loss: 0.0386 - val_accuracy: 0.9872 - val_specificity: 0.9962 - val_recall: 0.4335\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 5.6961e-05 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4243\n",
      "Epoch 9: val_accuracy did not improve from 0.99231\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 5.6961e-05 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4243 - val_loss: 0.0298 - val_accuracy: 0.9872 - val_specificity: 0.9952 - val_recall: 0.4022\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - ETA: 0s - loss: 2.8656e-05 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4193\n",
      "Epoch 10: val_accuracy did not improve from 0.99231\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 2.8656e-05 - accuracy: 1.0000 - specificity: 1.0000 - recall: 0.4193 - val_loss: 0.0271 - val_accuracy: 0.9897 - val_specificity: 0.9969 - val_recall: 0.4359\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f92b80c7970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=30,\n",
    "  use_multiprocessing=True,\n",
    "  callbacks=cd\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
